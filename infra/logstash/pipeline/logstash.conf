input {
  tcp {
    port => 5000
    codec => json_lines
  }
}

filter {
  # logstash-logback-encoder отправляет JSON напрямую через TCP с codec json_lines
  # Все поля уже доступны напрямую (level, message, service, @timestamp, logger_name, thread_name и т.д.)
  
  # Добавление метаданных для индексации на основе поля service
  mutate {
    add_field => { "[@metadata][index]" => "%{service}-logs-%{+YYYY.MM.dd}" }
  }
  
  # Если service не определен, используем значение по умолчанию
  if ![service] {
    mutate {
      add_field => { "service" => "unknown" }
    }
  }
  
  # Фильтрация чувствительных данных (пароли, токены)
  # Раскомментируйте, если нужно маскировать чувствительные данные
  # mutate {
  #   gsub => [
  #     "message", "(?i)(password|token|secret|key|api[_-]?key)=[^&\s\"']+", "\1=***",
  #     "message", "(?i)(\"password\"\\s*:\\s*\")([^\"]+)(\")", "\1***\3",
  #     "message", "(?i)(\"token\"\\s*:\\s*\")([^\"]+)(\")", "\1***\3"
  #   ]
  # }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    # Динамический индекс на основе поля service
    index => "%{[@metadata][index]}"
    # Или можно использовать фиксированные индексы:
    # index => "%{service}-logs-%{+YYYY.MM.dd}"
  }
  
  # Fallback на stdout для отладки (опционально, можно закомментировать в продакшене)
  stdout {
    codec => rubydebug
  }
}
